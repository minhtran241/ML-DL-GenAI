{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "writer = SummaryWriter(\"../runs/transfer_learning_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ants', 'bees']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "data_dir = \"../data/hymenoptera_data\"\n",
    "sets = [\"train\", \"val\"]\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in sets\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=4, shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in sets\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in sets}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    scheduler: lr_scheduler.LRScheduler,\n",
    "    num_epochs: int = 25,\n",
    ") -> nn.Module:\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(\n",
    "        model.state_dict()\n",
    "    )  # Do this to keep the best model weights\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print(f\"Epoch {epoch}/{num_epochs-1}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            labels_lst = []\n",
    "            preds_lst = []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    class_preds = [F.softmax(output, dim=0) for output in outputs]\n",
    "                    labels_lst.append(preds)\n",
    "                    preds_lst.append(class_preds)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            preds_lst = torch.cat([torch.stack(batch) for batch in preds_lst])\n",
    "            labels_lst = torch.cat(labels_lst)\n",
    "\n",
    "            print(preds_lst.shape, labels_lst.shape)\n",
    "            print(f\"Pred {preds_lst[:5]}\")\n",
    "            print(f\"Labels {labels_lst[:5]}\")\n",
    "\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "                classes = range(len(class_names))\n",
    "                for i in classes:\n",
    "                    labels_i = labels_lst == i # Get the labels of the class. == i means get the labels that are equal to i\n",
    "                    preds_i = preds_lst[:, i] # Get the probability of the class. [:, i] means get the ith column of the tensor\n",
    "                    writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "            writer.add_scalar(f\"{phase} loss\", epoch_loss, epoch)\n",
    "            writer.add_scalar(f\"{phase} accuracy\", epoch_acc, epoch)\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")\n",
    "\n",
    "# Freeze all layers except the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(in_features=num_ftrs, out_features=2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Scheduler\n",
    "step_lr_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer, step_size=7, gamma=0.1\n",
    ")  # For every 7 epochs, decrease the learning rate by 0.1\n",
    "\n",
    "# Finetune the model\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=step_lr_scheduler,\n",
    "    num_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dataloaders[\"train\"]))\n",
    "batch1 = inputs[0].to(device)\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "writer.add_image(\"Training Images\", out, 0)\n",
    "writer.add_graph(model, batch1.unsqueeze(0))\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
